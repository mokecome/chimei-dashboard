"""
å„ªåŒ–çš„ LLM åˆ†æå™¨ - æ”¯æŒå®Œæ•´å…§å®¹è™•ç†
"""
import requests
import re
import json
import time
from opencc import OpenCC
from typing import Dict, Optional

# é…ç½®
LLM_API_URL = 'http://192.168.50.123:11434/api/generate'
MODEL_NAME = 'qwen3:8b'
cc = OpenCC('s2t')

def clean_asr_tags(text: str) -> str:
    """æ¸…é™¤ ASR æ¨™è¨˜"""
    cleaned = re.sub(r'<[^>]+>', '', text)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    return cleaned.strip()

def calculate_dynamic_timeout(content_length: int) -> int:
    """
    æ ¹æ“šå…§å®¹é•·åº¦è¨ˆç®—å‹•æ…‹è¶…æ™‚æ™‚é–“
    åŸºæº–ï¼šæ¯ 1000 å­—ç¬¦éœ€è¦ç´„ 60 ç§’è™•ç†æ™‚é–“
    """
    base_timeout = 180  # åŸºç¤è¶…æ™‚ 3 åˆ†é˜
    chars_per_minute = 1000  # æ¯åˆ†é˜è™•ç†å­—ç¬¦æ•¸
    
    # è¨ˆç®—éœ€è¦çš„é¡å¤–æ™‚é–“
    extra_time = (content_length / chars_per_minute) * 60
    
    # ç¸½è¶…æ™‚æ™‚é–“ï¼Œæœ€å¤§ 10 åˆ†é˜
    total_timeout = min(600, base_timeout + extra_time)
    
    return int(total_timeout)

def call_llm_streaming(transcript: str, product_list: str = "", 
                      feedback_list: str = "") -> Dict:
    """
    ä½¿ç”¨æµå¼ API è™•ç†é•·å…§å®¹ï¼Œé¿å…è¶…æ™‚
    """
    # å„ªåŒ–çš„æç¤ºè©æ¨¡æ¿
    prompt_template = (
        "/no_think\n"
        "/role:ä½ æ˜¯å°ç£é£Ÿå“æ¥­çš„å®¢æœè³‡æ–™æ¨™è¨»å°ˆå®¶ã€‚\n"
        "/task:åˆ†æä»¥ä¸‹å®¢æœå°è©±ï¼Œç›´æ¥è¼¸å‡ºJSONçµæœã€‚\n\n"
        "è¦æ±‚ï¼š\n"
        "1. ä½¿ç”¨ç¹é«”ä¸­æ–‡\n"
        "2. æ‘˜è¦ä¿æŒåœ¨200å­—å…§\n"
        "3. åªè¼¸å‡ºJSONæ ¼å¼çµæœ\n\n"
        "JSONæ ¼å¼ï¼š\n"
        '{{\n'
        '  "product_name": "é£Ÿå“åç¨±ï¼ˆå¯å¤šå€‹ï¼Œç„¡å‰‡å¡«ã€Œç„¡ã€ï¼‰",\n'
        '  "evaluation_tendency": "æ­£é¢/è² é¢/ä¸­ç«‹",\n'
        '  "feedback_category": "å°è©±åˆ†é¡",\n'
        '  "feedback_summary": "å°è©±æ‘˜è¦ï¼ˆ200å­—å…§ï¼‰",\n'
        '  "detailed_content": "é—œéµå…§å®¹"\n'
        '}}\n\n'
    )
    
    # æ·»åŠ å¯é¸æ¸…å–®
    if product_list:
        prompt_template += f"å¯é¸ç”¢å“ï¼š{product_list}\n\n"
    if feedback_list:
        prompt_template += f"åˆ†é¡é¸é …ï¼š{feedback_list}\n\n"
    
    prompt_template += f"å®¢æœå°è©±ï¼š\n{transcript}\n\nJSONçµæœï¼š"
    
    # è¨ˆç®—è¶…æ™‚æ™‚é–“
    content_length = len(transcript)
    timeout = calculate_dynamic_timeout(content_length)
    
    print(f"ğŸ“Š å…§å®¹é•·åº¦ï¼š{content_length} å­—ç¬¦")
    print(f"â±ï¸  è¨­å®šè¶…æ™‚ï¼š{timeout} ç§’")
    
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt_template,
        "stream": True,  # å•Ÿç”¨æµå¼è™•ç†
        "temperature": 0,
        "top_p": 0.5,
        "options": {
            "num_ctx": 8192,  # å¢åŠ ä¸Šä¸‹æ–‡çª—å£
            "num_predict": 1000  # é™åˆ¶è¼¸å‡ºé•·åº¦
        }
    }
    
    try:
        print("ğŸ”„ é–‹å§‹æµå¼è™•ç†...")
        response = requests.post(
            LLM_API_URL,
            json=payload,
            stream=True,
            timeout=(30, timeout),  # (é€£æ¥è¶…æ™‚, è®€å–è¶…æ™‚)
            headers={'Connection': 'keep-alive'}
        )
        
        # é€å¡Šè®€å–éŸ¿æ‡‰
        full_response = ""
        start_time = time.time()
        chunk_count = 0
        
        for line in response.iter_lines():
            if line:
                try:
                    chunk = json.loads(line)
                    if chunk.get("response"):
                        full_response += chunk["response"]
                        chunk_count += 1
                        
                        # æ¯ 10 å€‹å¡Šé¡¯ç¤ºé€²åº¦
                        if chunk_count % 10 == 0:
                            elapsed = time.time() - start_time
                            print(f"  è™•ç†ä¸­... ({elapsed:.1f}ç§’)")
                    
                    # æª¢æŸ¥æ˜¯å¦å®Œæˆ
                    if chunk.get("done", False):
                        print(f"âœ… æµå¼è™•ç†å®Œæˆ (å…± {chunk_count} å¡Š)")
                        break
                        
                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    print(f"âš ï¸ è™•ç†å¡Šæ™‚å‡ºéŒ¯: {e}")
                    continue
        
        return parse_llm_response(full_response)
        
    except requests.exceptions.Timeout:
        print("âŒ æµå¼è™•ç†è¶…æ™‚")
        return fallback_analysis(transcript)
    except Exception as e:
        print(f"âŒ æµå¼è™•ç†å¤±æ•—: {str(e)}")
        return {"error": f"æµå¼è™•ç†å¤±æ•—: {str(e)}"}

def call_llm_with_retry(transcript: str, product_list: str = "", 
                       feedback_list: str = "", max_retries: int = 2) -> Dict:
    """
    å¸¶é‡è©¦æ©Ÿåˆ¶çš„ LLM èª¿ç”¨ï¼ˆéæµå¼å‚™ç”¨æ–¹æ¡ˆï¼‰
    """
    # ç°¡åŒ–çš„æç¤ºè©
    prompt = f"""
/no_think
ä½ æ˜¯å®¢æœåˆ†æå°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹å°è©±ä¸¦è¼¸å‡ºJSONï¼š
{{
  "product_name": "ç”¢å“åç¨±æˆ–ç„¡",
  "evaluation_tendency": "æ­£é¢/è² é¢/ä¸­ç«‹",
  "feedback_category": "åˆ†é¡",
  "feedback_summary": "æ‘˜è¦(200å­—å…§)"
}}

å°è©±ï¼š{transcript[:3000]}...

JSONï¼š"""
    
    # å‹•æ…‹è¶…æ™‚
    timeout = calculate_dynamic_timeout(len(transcript))
    
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "temperature": 0,
        "top_p": 0.5
    }
    
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ ç¬¬ {attempt + 1} æ¬¡å˜—è©¦...")
            resp = requests.post(LLM_API_URL, json=payload, timeout=timeout)
            
            if resp.status_code == 200:
                result = resp.json().get("response", "")
                return parse_llm_response(result)
            
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                print(f"â° è¶…æ™‚ï¼Œç­‰å¾…å¾Œé‡è©¦...")
                time.sleep(10)
                continue
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            
    return fallback_analysis(transcript)

def parse_llm_response(result: str) -> Dict:
    """è§£æ LLM éŸ¿æ‡‰"""
    # è½‰ç¹é«”
    result = cc.convert(result)
    
    # å˜—è©¦æå– JSON
    match = re.search(r'\{[^{}]*\}', result, re.DOTALL)
    
    if match:
        try:
            parsed = json.loads(match.group(0))
            
            # ç¢ºä¿æ‰€æœ‰å¿…è¦å­—æ®µå­˜åœ¨
            required_fields = ["product_name", "evaluation_tendency", 
                             "feedback_category", "feedback_summary"]
            
            for field in required_fields:
                if field not in parsed:
                    parsed[field] = get_default_value(field)
            
            # é™åˆ¶æ‘˜è¦é•·åº¦ï¼ˆä½†ä¸æˆªæ–·å…§å®¹ï¼‰
            if len(parsed.get("feedback_summary", "")) > 500:
                parsed["feedback_summary"] = parsed["feedback_summary"][:497] + "..."
            
            return parsed
            
        except json.JSONDecodeError:
            print("âš ï¸ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ")
    
    return fallback_analysis(result)

def fallback_analysis(transcript: str) -> Dict:
    """
    åŸºæ–¼è¦å‰‡çš„å‚™ç”¨åˆ†æï¼ˆä¸ä¾è³´ LLMï¼‰
    ä¿ç•™å®Œæ•´å…§å®¹ï¼Œæä¾›åŸºç¤åˆ†æ
    """
    # é—œéµè©åˆ†æ
    positive_words = ["è¬è¬", "å¾ˆå¥½", "æ»¿æ„", "ä¸éŒ¯", "å–œæ­¡", "æ£’", "è®š", "å„ªç§€"]
    negative_words = ["å•é¡Œ", "æŠ•è¨´", "é€€è²¨", "ä¸æ»¿", "å·®", "çˆ›", "å¤±æœ›", "ç³Ÿç³•"]
    
    # ç”¢å“é—œéµè©
    product_keywords = {
        "æ°´é¤ƒ": ["æ°´é¤ƒ", "é¤ƒå­"],
        "åŒ…å­": ["åŒ…å­", "é¥…é ­"],
        "æ¹¯åœ“": ["æ¹¯åœ“", "å…ƒå®µ"],
        "é¤›é£©": ["é¤›é£©", "é›²å"],
        "ç‡’è³£": ["ç‡’è³£", "ç‡’éº¥"]
    }
    
    # çµ±è¨ˆæƒ…ç·’
    text_lower = transcript.lower()
    positive_count = sum(1 for word in positive_words if word in text_lower)
    negative_count = sum(1 for word in negative_words if word in text_lower)
    
    # åˆ¤æ–·æƒ…ç·’
    if positive_count > negative_count * 2:
        sentiment = "æ­£é¢"
    elif negative_count > positive_count * 2:
        sentiment = "è² é¢"
    else:
        sentiment = "ä¸­ç«‹"
    
    # è­˜åˆ¥ç”¢å“
    found_products = []
    for product, keywords in product_keywords.items():
        if any(keyword in text_lower for keyword in keywords):
            found_products.append(product)
    
    # åˆ¤æ–·é¡åˆ¥
    if any(word in text_lower for word in ["é€€", "æ›", "è³ "]):
        category = "é€€æ›è²¨è«®è©¢"
    elif any(word in text_lower for word in ["è²·", "è¨‚", "è³¼"]):
        category = "è¨‚è³¼è«®è©¢"
    elif any(word in text_lower for word in ["å•é¡Œ", "æŠ•è¨´"]):
        category = "å•é¡Œåé¥‹"
    else:
        category = "ä¸€èˆ¬è«®è©¢"
    
    return {
        "product_name": found_products if found_products else ["ç„¡"],
        "evaluation_tendency": sentiment,
        "feedback_category": category,
        "feedback_summary": "ç³»çµ±è‡ªå‹•åˆ†æå®Œæˆï¼Œä¿ç•™å®Œæ•´å°è©±å…§å®¹ï¼Œå»ºè­°äººå·¥è¤‡æ ¸ç¢ºèªåˆ†æçµæœã€‚",
        "detailed_content": "å®Œæ•´å…§å®¹å·²ä¿å­˜"
    }

def get_default_value(field: str) -> any:
    """ç²å–å­—æ®µé»˜èªå€¼"""
    defaults = {
        "product_name": ["ç„¡"],
        "evaluation_tendency": "ä¸­ç«‹",
        "feedback_category": "ä¸€èˆ¬è«®è©¢",
        "feedback_summary": "å¾…åˆ†æ",
        "detailed_content": ""
    }
    return defaults.get(field, "")

def analyze_feedback(transcript: str, product_list: str = "", 
                    feedback_list: str = "") -> Dict:
    """
    ä¸»åˆ†æå‡½æ•¸ - å„ªåŒ–ç‰ˆæœ¬
    """
    # æ¸…ç†è½‰éŒ„æ–‡æœ¬
    cleaned_transcript = clean_asr_tags(transcript)
    
    print(f"\nğŸ¯ é–‹å§‹åˆ†æ (é•·åº¦: {len(cleaned_transcript)} å­—ç¬¦)")
    
    # å„ªå…ˆä½¿ç”¨æµå¼è™•ç†
    result = call_llm_streaming(cleaned_transcript, product_list, feedback_list)
    
    # å¦‚æœæµå¼è™•ç†å¤±æ•—ï¼Œå˜—è©¦æ¨™æº–æ–¹å¼
    if "error" in result:
        print("âš ï¸ æµå¼è™•ç†å¤±æ•—ï¼Œå˜—è©¦æ¨™æº–æ–¹å¼...")
        result = call_llm_with_retry(cleaned_transcript, product_list, feedback_list)
    
    # ç¢ºä¿è¿”å›å®Œæ•´çš„åˆ†æçµæœ
    if "error" not in result:
        print("âœ… åˆ†ææˆåŠŸå®Œæˆ")
    else:
        print(f"âŒ åˆ†æå¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    return result

# ä¿æŒèˆ‡åŸå§‹æ¥å£å…¼å®¹
call_llm = analyze_feedback

if __name__ == "__main__":
    # æ¸¬è©¦
    test_transcript = "å®¢æˆ¶è©¢å•æ°´é¤ƒçš„ä¿å­˜æ–¹å¼ï¼Œè¡¨ç¤ºå¾ˆæ»¿æ„ç”¢å“å“è³ª..."
    result = analyze_feedback(test_transcript)
    print(json.dumps(result, ensure_ascii=False, indent=2))